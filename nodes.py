from transformers import AutoModelForImageSegmentation
import torch
from torchvision import transforms
import numpy as np
from PIL import Image
import torch.nn.functional as F
import comfy.model_management as mm
import os
import gc
import weakref
import math

torch.set_float32_matmul_precision(["high", "highest"][0])

transform_image = transforms.Compose(
    [
        transforms.Resize((1024, 1024)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ]
)

current_path  = os.getcwd()

## ComfyUI portable standalone build for Windows 
model_path = os.path.join(current_path, "ComfyUI"+os.sep+"models"+os.sep+"BiRefNet")

# å…¨å±€æ¨¡å‹ç¼“å­˜å­—å…¸
_model_cache = {}
_device_cache = {}

def get_available_memory(device):
    """è·å–å¯ç”¨æ˜¾å­˜"""
    if device.startswith('cuda'):
        try:
            current_memory = torch.cuda.memory_allocated() / (1024**3)  # GB
            total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
            available_memory = total_memory - current_memory
            return available_memory
        except:
            return 4.0  # é»˜è®¤4GB
    return 16.0  # CPUæˆ–å…¶ä»–è®¾å¤‡é»˜è®¤å¤§å†…å­˜

def calculate_optimal_resolution(image_size, device, target_memory_gb=2.0):
    """æ ¹æ®å¯ç”¨æ˜¾å­˜è®¡ç®—æœ€ä¼˜åˆ†è¾¨ç‡"""
    w, h = image_size
    available_memory = get_available_memory(device)
    
    # å¦‚æœå¯ç”¨æ˜¾å­˜å……è¶³ï¼Œä½¿ç”¨è¾ƒé«˜åˆ†è¾¨ç‡
    if available_memory > 6.0:
        max_res = 1024
    elif available_memory > 4.0:
        max_res = 768
    elif available_memory > 2.0:
        max_res = 512
    else:
        max_res = 384  # æç«¯æƒ…å†µä¸‹çš„æœ€å°åˆ†è¾¨ç‡
    
    # ç¡®ä¿ä¸è¶…è¿‡åŸå›¾å°ºå¯¸å¤ªå¤š
    original_max = max(w, h)
    if original_max < max_res:
        max_res = min(max_res, original_max + 128)  # é€‚å½“æ”¾å¤§ä½†ä¸è¿‡åº¦
    
    return max_res

def create_dynamic_transform(target_size):
    """åˆ›å»ºåŠ¨æ€çš„å›¾åƒå˜æ¢"""
    return transforms.Compose([
        transforms.Resize(target_size),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

def get_cached_model(model_name, local_model_path, load_local_model, device):
    """è·å–ç¼“å­˜çš„æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½"""
    cache_key = f"{model_name}_{local_model_path}_{load_local_model}"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ¨¡å‹
    if cache_key in _model_cache:
        model = _model_cache[cache_key]
        # æ£€æŸ¥è®¾å¤‡æ˜¯å¦åŒ¹é…
        if cache_key in _device_cache and _device_cache[cache_key] == device:
            return model
        else:
            # è®¾å¤‡ä¸åŒ¹é…ï¼Œç§»åŠ¨æ¨¡å‹åˆ°æ–°è®¾å¤‡
            model = model.to(device)
            _device_cache[cache_key] = device
            return model
    
    # åŠ è½½æ–°æ¨¡å‹å‰ï¼Œæ£€æŸ¥æ˜¾å­˜å¹¶æ¸…ç†
    if device.startswith('cuda'):
        available_mem = get_available_memory(device)
        print(f"\033[93må¯ç”¨æ˜¾å­˜: {available_mem:.1f}GB\033[0m")
        
        if available_mem < 3.0:  # å¦‚æœå¯ç”¨æ˜¾å­˜ä¸è¶³3GB
            torch.cuda.empty_cache()
            gc.collect()
            print("\033[93mæ˜¾å­˜ä¸è¶³ï¼Œå·²æ‰§è¡Œæ¸…ç†\033[0m")
    
    # åŠ è½½æ–°æ¨¡å‹
    print(f"\033[93mæ­£åœ¨åŠ è½½BiRefNetæ¨¡å‹åˆ°è®¾å¤‡: {device}\033[0m")
    
    if load_local_model:
        model = AutoModelForImageSegmentation.from_pretrained(
            local_model_path, trust_remote_code=True
        )
    else:
        model = AutoModelForImageSegmentation.from_pretrained(
            model_name, trust_remote_code=True
        )
    
    # ä½¿ç”¨ComfyUIçš„æ˜¾å­˜ç®¡ç†
    model = model.to(device)
    
    # ç¼“å­˜æ¨¡å‹
    _model_cache[cache_key] = model
    _device_cache[cache_key] = device
    
    return model

def clear_model_cache():
    """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
    global _model_cache, _device_cache
    for model in _model_cache.values():
        del model
    _model_cache.clear()
    _device_cache.clear()
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()

def tensor2pil(image):
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))

def pil2tensor(image):
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)

def resize_image_smart(image, max_size=1024, device="cuda"):
    """è¶…çº§æ™ºèƒ½resizeï¼Œæ ¹æ®æ˜¾å­˜åŠ¨æ€è°ƒæ•´"""
    image = image.convert('RGB')
    w, h = image.size
    
    # æ ¹æ®æ˜¾å­˜æƒ…å†µåŠ¨æ€è°ƒæ•´æœ€å¤§åˆ†è¾¨ç‡
    optimal_max_size = calculate_optimal_resolution((w, h), device)
    final_max_size = min(max_size, optimal_max_size)
    
    print(f"\033[96måŸå§‹åˆ†è¾¨ç‡: {w}x{h}, ç›®æ ‡æœ€å¤§åˆ†è¾¨ç‡: {final_max_size}\033[0m")
    
    # å¦‚æœå›¾ç‰‡å·²ç»å¾ˆå°ï¼Œä¸éœ€è¦resize
    if max(w, h) <= final_max_size:
        # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä½†ç¡®ä¿æ˜¯32çš„å€æ•°ï¼ˆå¯¹æ¨¡å‹æ›´å‹å¥½ï¼‰
        w = ((w + 31) // 32) * 32
        h = ((h + 31) // 32) * 32
        model_input_size = (w, h)
    else:
        # ç­‰æ¯”ç¼©æ”¾åˆ°final_max_size
        if w > h:
            new_w = final_max_size
            new_h = int(h * final_max_size / w)
        else:
            new_h = final_max_size
            new_w = int(w * final_max_size / h)
        
        # ç¡®ä¿å°ºå¯¸æ˜¯32çš„å€æ•°
        new_w = ((new_w + 31) // 32) * 32
        new_h = ((new_h + 31) // 32) * 32
        model_input_size = (new_w, new_h)
    
    image = image.resize(model_input_size, Image.BILINEAR)
    print(f"\033[96mè°ƒæ•´ååˆ†è¾¨ç‡: {model_input_size[0]}x{model_input_size[1]}\033[0m")
    return image

def safe_model_inference(model, input_tensor, device):
    """å®‰å…¨çš„æ¨¡å‹æ¨ç†ï¼ŒåŒ…å«å¤šçº§é™çº§ç­–ç•¥"""
    try:
        # ç¬¬ä¸€æ¬¡å°è¯•ï¼šæ­£å¸¸æ¨ç†
        with torch.no_grad():
            result = model(input_tensor)[-1].sigmoid()
            return result.cpu()
    except torch.cuda.OutOfMemoryError as e:
        print(f"\033[91mæ˜¾å­˜ä¸è¶³ï¼Œå°è¯•æ¸…ç†åé‡è¯•...\033[0m")
        
        # æ¸…ç†æ˜¾å­˜
        del input_tensor
        torch.cuda.empty_cache()
        gc.collect()
        
        # é‡æ–°åˆ›å»ºè¾“å…¥å¼ é‡ï¼Œä½†ä½¿ç”¨æ›´å°çš„åˆ†è¾¨ç‡
        raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†

colors = ["transparency", "green", "white", "red", "yellow", "blue", "black", "pink", "purple", "brown", "violet", "wheat", "whitesmoke", "yellowgreen", "turquoise", "tomato", "thistle", "teal", "tan", "steelblue", "springgreen", "snow", "slategrey", "slateblue", "skyblue", "orange"]

def get_device_by_name(device):
    """
    "device": (["auto", "cuda", "cpu", "mps", "xpu", "meta"],{"default": "auto"}), 
    """
    if device == 'auto':
        try:
            device = "cpu"
            if torch.cuda.is_available():
                device = "cuda"
            elif torch.backends.mps.is_available():
                device = "mps"
            elif torch.xpu.is_available():
                device = "xpu"
        except:
                raise AttributeError("What's your device(åˆ°åº•ç”¨ä»€ä¹ˆè®¾å¤‡è·‘çš„)ï¼Ÿ")
    print("\033[93mUse Device(ä½¿ç”¨è®¾å¤‡):", device, "\033[0m")
    return device


class BiRefNet_Hugo:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        
        return {
            "required": {
                "image": ("IMAGE",),
                "model": (["ZhengPeng7/BiRefNet", "ZhengPeng7/BiRefNet_HR", "ZhengPeng7/BiRefNet-portrait"],{"default": "ZhengPeng7/BiRefNet"}),
                "load_local_model": ("BOOLEAN", {"default": False}),
                "background_color_name": (colors,{"default": "transparency"}), 
                "device": (["auto", "cuda", "cpu", "mps", "xpu", "meta"],{"default": "auto"}),
                "max_resolution": ("INT", {"default": 768, "min": 384, "max": 1024, "step": 64}),
                "enable_memory_efficient": ("BOOLEAN", {"default": True}),
                "auto_resolution": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "local_model_path": ("STRING", {"default":model_path}),
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK",)
    RETURN_NAMES = ("image", "mask",)
    FUNCTION = "background_remove"
    CATEGORY = "ğŸ”¥BiRefNet"
  
    def background_remove(self, 
                          image, 
                          model,
                          load_local_model,
                          device, 
                          background_color_name,
                          max_resolution=768,
                          enable_memory_efficient=True,
                          auto_resolution=True,
                          *args, **kwargs
                          ):
        processed_images = []
        processed_masks = []
       
        device = get_device_by_name(device)
        
        # æ˜¾ç¤ºå½“å‰æ˜¾å­˜çŠ¶æ€
        if device.startswith('cuda'):
            available_mem = get_available_memory(device)
            print(f"\033[96må½“å‰å¯ç”¨æ˜¾å­˜: {available_mem:.1f}GB\033[0m")
        
        try:
            # è·å–ç¼“å­˜çš„æ¨¡å‹
            local_model_path = kwargs.get("local_model_path", model_path)
            birefnet = get_cached_model(model, local_model_path, load_local_model, device)
            
            # å¼ºåˆ¶å†…å­˜æ•ˆç‡æ¨¡å¼è¿›è¡Œå•å¼ å¤„ç†
            for idx, img_tensor in enumerate(image):
                print(f"\033[96mæ­£åœ¨å¤„ç†ç¬¬ {idx+1}/{len(image)} å¼ å›¾ç‰‡\033[0m")
                
                retry_count = 0
                max_retries = 3
                current_max_res = max_resolution
                
                while retry_count < max_retries:
                    try:
                        orig_image = tensor2pil(img_tensor)
                        w, h = orig_image.size
                        
                        # æ™ºèƒ½resize - æ ¹æ®æ˜¾å­˜è‡ªåŠ¨è°ƒæ•´åˆ†è¾¨ç‡
                        if auto_resolution:
                            resized_image = resize_image_smart(orig_image, current_max_res, device)
                        else:
                            # æ‰‹åŠ¨resize
                            if max(w, h) > current_max_res:
                                if w > h:
                                    new_w = current_max_res
                                    new_h = int(h * current_max_res / w)
                                else:
                                    new_h = current_max_res
                                    new_w = int(w * current_max_res / h)
                                # ç¡®ä¿æ˜¯32çš„å€æ•°
                                new_w = ((new_w + 31) // 32) * 32
                                new_h = ((new_h + 31) // 32) * 32
                                resized_image = orig_image.resize((new_w, new_h), Image.BILINEAR)
                            else:
                                resized_image = orig_image
                        
                        # åˆ›å»ºåŠ¨æ€transform
                        dynamic_transform = create_dynamic_transform(resized_image.size)
                        im_tensor = dynamic_transform(resized_image).unsqueeze(0)
                        im_tensor = im_tensor.to(device)
                        
                        # æ¨ç†å‰æ£€æŸ¥æ˜¾å­˜
                        if device.startswith('cuda'):
                            torch.cuda.empty_cache()
                        
                        # å®‰å…¨æ¨ç†
                        print(f"\033[96må¼€å§‹æ¨ç†ï¼Œåˆ†è¾¨ç‡: {resized_image.size}\033[0m")
                        with torch.no_grad():
                            result = birefnet(im_tensor)[-1].sigmoid()
                            
                            # ç«‹å³ç§»åˆ°CPUé‡Šæ”¾GPUæ˜¾å­˜
                            result = result.cpu()
                            
                            # æ¸…ç†ä¸­é—´å¼ é‡
                            del im_tensor
                            if device.startswith('cuda'):
                                torch.cuda.empty_cache()
                        
                        print(f"\033[92mæ¨ç†æˆåŠŸ!\033[0m")
                        
                        # åå¤„ç†
                        result = torch.squeeze(F.interpolate(result, size=(h, w), mode='bilinear', align_corners=False))
                        ma = torch.max(result)
                        mi = torch.min(result)
                        result = (result - mi) / (ma - mi + 1e-8)
                        
                        im_array = (result * 255).data.numpy().astype(np.uint8)
                        pil_im = Image.fromarray(np.squeeze(im_array))
                        
                        # ç”Ÿæˆæœ€ç»ˆå›¾åƒ
                        if background_color_name == 'transparency':
                            color = (0, 0, 0, 0)
                            mode = "RGBA"
                        else:
                            color = background_color_name
                            mode = "RGB"
                        
                        new_im = Image.new(mode, pil_im.size, color)
                        new_im.paste(orig_image, mask=pil_im)
                        
                        new_im_tensor = pil2tensor(new_im)
                        pil_im_tensor = pil2tensor(pil_im)
                        
                        processed_images.append(new_im_tensor)
                        processed_masks.append(pil_im_tensor)
                        
                        # æ¸…ç†ä¸­é—´å˜é‡
                        del result, im_array, pil_im, new_im
                        
                        # æˆåŠŸå¤„ç†ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                        break
                        
                    except torch.cuda.OutOfMemoryError as e:
                        retry_count += 1
                        print(f"\033[91mæ˜¾å­˜ä¸è¶³ (å°è¯• {retry_count}/{max_retries})ï¼Œé™ä½åˆ†è¾¨ç‡é‡è¯•...\033[0m")
                        
                        # æ¸…ç†æ˜¾å­˜
                        if 'im_tensor' in locals():
                            del im_tensor
                        if 'result' in locals():
                            del result
                        torch.cuda.empty_cache()
                        gc.collect()
                        
                        # é™ä½åˆ†è¾¨ç‡
                        current_max_res = max(384, current_max_res - 128)
                        print(f"\033[93mé™ä½åˆ†è¾¨ç‡åˆ°: {current_max_res}\033[0m")
                        
                        if retry_count >= max_retries:
                            print(f"\033[91mé‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œè·³è¿‡æ­¤å›¾ç‰‡\033[0m")
                            # åˆ›å»ºä¸€ä¸ªç©ºç™½çš„ç»“æœ
                            orig_image = tensor2pil(img_tensor)
                            empty_mask = Image.new('L', orig_image.size, 0)
                            processed_images.append(pil2tensor(orig_image))
                            processed_masks.append(pil2tensor(empty_mask))
                            break
                    
                    except Exception as e:
                        print(f"\033[91må¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}\033[0m")
                        # åœ¨å‡ºé”™æ—¶ä¹Ÿè¦æ¸…ç†æ˜¾å­˜
                        if device.startswith('cuda'):
                            torch.cuda.empty_cache()
                        raise e
                
                # æ¯å¼ å›¾ç‰‡å¤„ç†åæ¸…ç†
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
                    gc.collect()

            new_ims = torch.cat(processed_images, dim=0)
            new_masks = torch.cat(processed_masks, dim=0)

            print(f"\033[92mæ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆ!\033[0m")
            return new_ims, new_masks
            
        except Exception as e:
            print(f"\033[91mBiRefNetå¤„ç†å¤±è´¥: {str(e)}\033[0m")
            # å‘ç”Ÿé”™è¯¯æ—¶æ¸…ç†æ˜¾å­˜
            if device.startswith('cuda'):
                torch.cuda.empty_cache()
            gc.collect()
            raise e


# æ·»åŠ æ¸…ç†å‡½æ•°èŠ‚ç‚¹
class BiRefNet_ClearCache:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "trigger": ("BOOLEAN", {"default": True}),
            }
        }

    RETURN_TYPES = ("BOOLEAN",)
    RETURN_NAMES = ("success",)
    FUNCTION = "clear_cache"
    CATEGORY = "ğŸ”¥BiRefNet"
    
    def clear_cache(self, trigger):
        """æ‰‹åŠ¨æ¸…ç†BiRefNetæ¨¡å‹ç¼“å­˜"""
        if trigger:
            clear_model_cache()
            print("\033[92mBiRefNetæ¨¡å‹ç¼“å­˜å·²æ¸…ç†\033[0m")
        return (True,)


NODE_CLASS_MAPPINGS = {
    "BiRefNet_Hugo": BiRefNet_Hugo,
    "BiRefNet_ClearCache": BiRefNet_ClearCache
}

# A dictionary that contains the friendly/humanly readable titles for the nodes
NODE_DISPLAY_NAME_MAPPINGS = {
    "BiRefNet_Hugo": "ğŸ”¥BiRefNet",
    "BiRefNet_ClearCache": "ğŸ”¥BiRefNetæ¸…ç†ç¼“å­˜"
}
